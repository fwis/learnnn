{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved image to mnist_image_epoch0_batch0_idx0.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx1.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx2.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx3.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx4.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx5.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx6.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx7.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx8.bmp\n",
      "Saved image to mnist_image_epoch0_batch0_idx9.bmp\n",
      "Train Epoch: 0 [0/60000 (0%)]\t\n",
      "Train Epoch: 0 [6400/60000 (11%)]\t\n",
      "Train Epoch: 0 [12800/60000 (21%)]\t\n",
      "Train Epoch: 0 [19200/60000 (32%)]\t\n",
      "Train Epoch: 0 [25600/60000 (43%)]\t\n",
      "Train Epoch: 0 [32000/60000 (53%)]\t\n",
      "Train Epoch: 0 [38400/60000 (64%)]\t\n",
      "Train Epoch: 0 [44800/60000 (75%)]\t\n",
      "Train Epoch: 0 [51200/60000 (85%)]\t\n",
      "Train Epoch: 0 [57600/60000 (96%)]\t\n",
      "Train Epoch: 1 [0/60000 (0%)]\t\n",
      "Train Epoch: 1 [6400/60000 (11%)]\t\n",
      "Train Epoch: 1 [12800/60000 (21%)]\t\n",
      "Train Epoch: 1 [19200/60000 (32%)]\t\n",
      "Train Epoch: 1 [25600/60000 (43%)]\t\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t\n",
      "Train Epoch: 1 [38400/60000 (64%)]\t\n",
      "Train Epoch: 1 [44800/60000 (75%)]\t\n",
      "Train Epoch: 1 [51200/60000 (85%)]\t\n",
      "Train Epoch: 1 [57600/60000 (96%)]\t\n",
      "Train Epoch: 2 [0/60000 (0%)]\t\n",
      "Train Epoch: 2 [6400/60000 (11%)]\t\n",
      "Train Epoch: 2 [12800/60000 (21%)]\t\n",
      "Train Epoch: 2 [19200/60000 (32%)]\t\n",
      "Train Epoch: 2 [25600/60000 (43%)]\t\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t\n",
      "Train Epoch: 2 [38400/60000 (64%)]\t\n",
      "Train Epoch: 2 [44800/60000 (75%)]\t\n",
      "Train Epoch: 2 [51200/60000 (85%)]\t\n",
      "Train Epoch: 2 [57600/60000 (96%)]\t\n",
      "Train Epoch: 3 [0/60000 (0%)]\t\n",
      "Train Epoch: 3 [6400/60000 (11%)]\t\n",
      "Train Epoch: 3 [12800/60000 (21%)]\t\n",
      "Train Epoch: 3 [19200/60000 (32%)]\t\n",
      "Train Epoch: 3 [25600/60000 (43%)]\t\n",
      "Train Epoch: 3 [32000/60000 (53%)]\t\n",
      "Train Epoch: 3 [38400/60000 (64%)]\t\n",
      "Train Epoch: 3 [44800/60000 (75%)]\t\n",
      "Train Epoch: 3 [51200/60000 (85%)]\t\n",
      "Train Epoch: 3 [57600/60000 (96%)]\t\n",
      "Train Epoch: 4 [0/60000 (0%)]\t\n",
      "Train Epoch: 4 [6400/60000 (11%)]\t\n",
      "Train Epoch: 4 [12800/60000 (21%)]\t\n",
      "Train Epoch: 4 [19200/60000 (32%)]\t\n",
      "Train Epoch: 4 [25600/60000 (43%)]\t\n",
      "Train Epoch: 4 [32000/60000 (53%)]\t\n",
      "Train Epoch: 4 [38400/60000 (64%)]\t\n",
      "Train Epoch: 4 [44800/60000 (75%)]\t\n",
      "Train Epoch: 4 [51200/60000 (85%)]\t\n",
      "Train Epoch: 4 [57600/60000 (96%)]\t\n",
      "Train Epoch: 5 [0/60000 (0%)]\t\n",
      "Train Epoch: 5 [6400/60000 (11%)]\t\n",
      "Train Epoch: 5 [12800/60000 (21%)]\t\n",
      "Train Epoch: 5 [19200/60000 (32%)]\t\n",
      "Train Epoch: 5 [25600/60000 (43%)]\t\n",
      "Train Epoch: 5 [32000/60000 (53%)]\t\n",
      "Train Epoch: 5 [38400/60000 (64%)]\t\n",
      "Train Epoch: 5 [44800/60000 (75%)]\t\n",
      "Train Epoch: 5 [51200/60000 (85%)]\t\n",
      "Train Epoch: 5 [57600/60000 (96%)]\t\n",
      "Train Epoch: 6 [0/60000 (0%)]\t\n",
      "Train Epoch: 6 [6400/60000 (11%)]\t\n",
      "Train Epoch: 6 [12800/60000 (21%)]\t\n",
      "Train Epoch: 6 [19200/60000 (32%)]\t\n",
      "Train Epoch: 6 [25600/60000 (43%)]\t\n",
      "Train Epoch: 6 [32000/60000 (53%)]\t\n",
      "Train Epoch: 6 [38400/60000 (64%)]\t\n",
      "Train Epoch: 6 [44800/60000 (75%)]\t\n",
      "Train Epoch: 6 [51200/60000 (85%)]\t\n",
      "Train Epoch: 6 [57600/60000 (96%)]\t\n",
      "Train Epoch: 7 [0/60000 (0%)]\t\n",
      "Train Epoch: 7 [6400/60000 (11%)]\t\n",
      "Train Epoch: 7 [12800/60000 (21%)]\t\n",
      "Train Epoch: 7 [19200/60000 (32%)]\t\n",
      "Train Epoch: 7 [25600/60000 (43%)]\t\n",
      "Train Epoch: 7 [32000/60000 (53%)]\t\n",
      "Train Epoch: 7 [38400/60000 (64%)]\t\n",
      "Train Epoch: 7 [44800/60000 (75%)]\t\n",
      "Train Epoch: 7 [51200/60000 (85%)]\t\n",
      "Train Epoch: 7 [57600/60000 (96%)]\t\n",
      "Train Epoch: 8 [0/60000 (0%)]\t\n",
      "Train Epoch: 8 [6400/60000 (11%)]\t\n",
      "Train Epoch: 8 [12800/60000 (21%)]\t\n",
      "Train Epoch: 8 [19200/60000 (32%)]\t\n",
      "Train Epoch: 8 [25600/60000 (43%)]\t\n",
      "Train Epoch: 8 [32000/60000 (53%)]\t\n",
      "Train Epoch: 8 [38400/60000 (64%)]\t\n",
      "Train Epoch: 8 [44800/60000 (75%)]\t\n",
      "Train Epoch: 8 [51200/60000 (85%)]\t\n",
      "Train Epoch: 8 [57600/60000 (96%)]\t\n",
      "Train Epoch: 9 [0/60000 (0%)]\t\n",
      "Train Epoch: 9 [6400/60000 (11%)]\t\n",
      "Train Epoch: 9 [12800/60000 (21%)]\t\n",
      "Train Epoch: 9 [19200/60000 (32%)]\t\n",
      "Train Epoch: 9 [25600/60000 (43%)]\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):  \u001b[38;5;66;03m# 假设我们训练10个epoch\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#optimizer.zero_grad()\u001b[39;49;00m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#output = model(data)\u001b[39;49;00m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#loss = criterion(output, target)\u001b[39;49;00m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#loss.backward()\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#optimizer.step()\u001b[39;49;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# 新增代码：保存图像为BMP文件\u001b[39;49;00m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 仅在第一个epoch的第一个batch时保存图像，避免大量保存\u001b[39;49;00m\n\u001b[0;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 保存前10张图像为例\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\MyApps\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32md:\\MyApps\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32md:\\MyApps\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32md:\\MyApps\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    143\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32md:\\MyApps\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32md:\\MyApps\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyApps\\anaconda3\\envs\\py311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    174\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 定义CNN模型\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.fc1 = nn.Linear(7*7*64, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7*7*64)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型\n",
    "model = CNNNet()\n",
    "\n",
    "# 加载MNIST数据集\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# 设置损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(10):  # 假设我们训练10个epoch\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        '''\n",
    "        # 新增代码：保存图像为BMP文件\n",
    "        if batch_idx == 0 and epoch == 0:  # 仅在第一个epoch的第一个batch时保存图像，避免大量保存\n",
    "            for i in range(min(len(data), 10)):  # 保存前10张图像为例\n",
    "                img = data[i][0]  # 因为MNIST是灰度图像，所以取第一个通道\n",
    "                img = img.detach().numpy()  # 转换为numpy数组\n",
    "                img = img.squeeze()  # 移除可能的单维度条目\n",
    "                img = (img - img.min()) / (img.max() - img.min()) * 255  # 归一化到0-255\n",
    "                img = img.astype(np.uint8)  # 转为无符号整型\n",
    "                filename = f'mnist_image_epoch{epoch}_batch{batch_idx}_idx{i}.bmp'\n",
    "                cv2.imwrite(filename, img)  # 使用OpenCV保存图像，确保已安装cv2库\n",
    "                print(f'Saved image to {filename}')\n",
    "        '''\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "            #print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\t')\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "print('Train finished!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
